{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphAutoencoder .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URiQndrL5enj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrGzsj3X5qww",
        "outputId": "7fab0cd4-3d86-46d7-e1b3-ffdeaad86c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (747 kB)\n",
            "\u001b[K     |████████████████████████████████| 747 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 546 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=9ea02b86f0d590c15c4fc8a860c1e9b838c4383be0d9e45d30d5540bef1541a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric \n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv, VGAE, GAE\n",
        "from torch_geometric.utils import train_test_split_edges "
      ],
      "metadata": {
        "id": "Ey3RsPq3M-1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=T.NormalizeFeatures())\n",
        "dataset.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ht4Z_sNcmP",
        "outputId": "28ab49ff-d678-4ffa-cf2f-21f501a94969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]\n",
        "data.train_mask = data.val_mask = data.test_mask = None"
      ],
      "metadata": {
        "id": "RpDD0DhfONri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnfZfsyWB62E",
        "outputId": "e3c67b08-81d9-4f39-b2df-f0f8c2505448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch_geometric.datasets.planetoid.Planetoid"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_test_split_edges(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTC67DcMcmbA",
        "outputId": "a5271d40-0016-484e-fe88-f62624b6a874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data\n",
        "#edge index = adjacency matrix, test_neg_edges -> edges in test set that are not in the graph, test_pos_edge_index -> edges in test set that are in graph, x -> feature matrix, y -> labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYUbQKqxu6md",
        "outputId": "93b63b06-8f1a-42f3-d4a3-cc56c7445329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[3327, 3703], y=[3327], val_pos_edge_index=[2, 227], test_pos_edge_index=[2, 455], train_pos_edge_index=[2, 7740], train_neg_adj_mask=[3327, 3327], val_neg_edge_index=[2, 227], test_neg_edge_index=[2, 455])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define encoder\n",
        "#in_channels -> number of features \n",
        "#out_channels -> 2 * out_channels --> because we have 2 convolutional layers. We go from the input features to double of output features and then in 2nd layer we go from double of output features we go to out features (size of embedding we want to produce)\n"
      ],
      "metadata": {
        "id": "56tIGWQjvboM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n"
      ],
      "metadata": {
        "id": "aqC48MM3whcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the autoencoder"
      ],
      "metadata": {
        "id": "rFSjJ-H-dm0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "out_channels = 2 #embedding in 2 dimensions\n",
        "num_features = data.edge_index\n",
        "epochs = 100\n",
        "\n",
        "#Model\n",
        "model = GAE(GCNEncoder(num_features, out_channels))\n",
        "\n",
        "#Move to GPU, if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "x = data.x.to(device)\n",
        "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
        "\n",
        "#Initialize the optimizer\n",
        "optimizer =torch.optim.Adam(model.parameters(), lr = 0.01)\n"
      ],
      "metadata": {
        "id": "8p0yi2LVdqsn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "3f4f0394-5e5c-4699-b05f-28b388f3e6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-10c20d7a504a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGCNEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Move to GPU, if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4d5d84c13cd2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGCNEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cached only for transductive learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cached only for transductive learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, improved, cached, add_self_loops, normalize, bias, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         self.lin = Linear(in_channels, out_channels, bias=False,\n\u001b[0;32m--> 140\u001b[0;31m                           weight_initializer='glorot')\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, bias, weight_initializer, bias_initializer)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtY4uP2rtU9u",
        "outputId": "14a9c9fb-4f8b-4053-bb26-cf2449a9d6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GAE(\n",
              "  (encoder): GCNEncoder(\n",
              "    (conv1): GCNConv(3703, 4)\n",
              "    (conv2): GCNConv(4, 2)\n",
              "  )\n",
              "  (decoder): InnerProductDecoder()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_elOWpXIupq3",
        "outputId": "636c04e3-2110-464d-c9fe-82de46140f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T_destination',\n",
              " '__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_apply',\n",
              " '_backward_hooks',\n",
              " '_buffers',\n",
              " '_call_impl',\n",
              " '_forward_hooks',\n",
              " '_forward_pre_hooks',\n",
              " '_get_backward_hooks',\n",
              " '_get_name',\n",
              " '_is_full_backward_hook',\n",
              " '_load_from_state_dict',\n",
              " '_load_state_dict_pre_hooks',\n",
              " '_maybe_warn_non_full_backward_hook',\n",
              " '_modules',\n",
              " '_named_members',\n",
              " '_non_persistent_buffers_set',\n",
              " '_parameters',\n",
              " '_register_load_state_dict_pre_hook',\n",
              " '_register_state_dict_hook',\n",
              " '_replicate_for_data_parallel',\n",
              " '_save_to_state_dict',\n",
              " '_slow_forward',\n",
              " '_state_dict_hooks',\n",
              " '_version',\n",
              " 'add_module',\n",
              " 'apply',\n",
              " 'bfloat16',\n",
              " 'buffers',\n",
              " 'children',\n",
              " 'cpu',\n",
              " 'cuda',\n",
              " 'decode',\n",
              " 'decoder',\n",
              " 'double',\n",
              " 'dump_patches',\n",
              " 'encode',\n",
              " 'encoder',\n",
              " 'eval',\n",
              " 'extra_repr',\n",
              " 'float',\n",
              " 'forward',\n",
              " 'get_buffer',\n",
              " 'get_extra_state',\n",
              " 'get_parameter',\n",
              " 'get_submodule',\n",
              " 'half',\n",
              " 'load_state_dict',\n",
              " 'modules',\n",
              " 'named_buffers',\n",
              " 'named_children',\n",
              " 'named_modules',\n",
              " 'named_parameters',\n",
              " 'parameters',\n",
              " 'recon_loss',\n",
              " 'register_backward_hook',\n",
              " 'register_buffer',\n",
              " 'register_forward_hook',\n",
              " 'register_forward_pre_hook',\n",
              " 'register_full_backward_hook',\n",
              " 'register_parameter',\n",
              " 'requires_grad_',\n",
              " 'reset_parameters',\n",
              " 'set_extra_state',\n",
              " 'share_memory',\n",
              " 'state_dict',\n",
              " 'test',\n",
              " 'to',\n",
              " 'to_empty',\n",
              " 'train',\n",
              " 'training',\n",
              " 'type',\n",
              " 'xpu',\n",
              " 'zero_grad']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TENSORBOARD Implementation"
      ],
      "metadata": {
        "id": "zC2f-9nQwbD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "0NgdagKzvwBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "out_channels = 2 #embedding in 2 dimensions\n",
        "num_features = dataset.num_features\n",
        "epochs = 100\n",
        "\n",
        "#Model\n",
        "model = GAE(GCNEncoder(num_features, out_channels))\n",
        "\n",
        "#Move to GPU, if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "x = data.x.to(device)\n",
        "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
        "\n",
        "#Initialize the optimizer\n",
        "optimizer =torch.optim.Adam(model.parameters(), lr = 0.01)\n"
      ],
      "metadata": {
        "id": "yiShGZNywgIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter('runs/GAE_experiment'+'2d_100_epochs')"
      ],
      "metadata": {
        "id": "wrA4VaLfwo9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train()\n",
        "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
        "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
        "    \n",
        "    \n",
        "    writer.add_scalar('auc train',auc,epoch) # new line\n",
        "    writer.add_scalar('ap train',ap,epoch)   # new line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OP5ue2Fw3So",
        "outputId": "be7648d2-b176-4a63-aca4-494ab6f268f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, AUC: 0.5964, AP: 0.6346\n",
            "Epoch: 002, AUC: 0.6045, AP: 0.6515\n",
            "Epoch: 003, AUC: 0.6116, AP: 0.6567\n",
            "Epoch: 004, AUC: 0.6156, AP: 0.6610\n",
            "Epoch: 005, AUC: 0.6180, AP: 0.6639\n",
            "Epoch: 006, AUC: 0.6204, AP: 0.6662\n",
            "Epoch: 007, AUC: 0.6212, AP: 0.6681\n",
            "Epoch: 008, AUC: 0.6219, AP: 0.6703\n",
            "Epoch: 009, AUC: 0.6242, AP: 0.6730\n",
            "Epoch: 010, AUC: 0.6254, AP: 0.6750\n",
            "Epoch: 011, AUC: 0.6258, AP: 0.6761\n",
            "Epoch: 012, AUC: 0.6264, AP: 0.6780\n",
            "Epoch: 013, AUC: 0.6266, AP: 0.6801\n",
            "Epoch: 014, AUC: 0.6264, AP: 0.6822\n",
            "Epoch: 015, AUC: 0.6257, AP: 0.6843\n",
            "Epoch: 016, AUC: 0.6250, AP: 0.6861\n",
            "Epoch: 017, AUC: 0.6238, AP: 0.6874\n",
            "Epoch: 018, AUC: 0.6230, AP: 0.6890\n",
            "Epoch: 019, AUC: 0.6223, AP: 0.6900\n",
            "Epoch: 020, AUC: 0.6219, AP: 0.6908\n",
            "Epoch: 021, AUC: 0.6216, AP: 0.6915\n",
            "Epoch: 022, AUC: 0.6213, AP: 0.6917\n",
            "Epoch: 023, AUC: 0.6219, AP: 0.6925\n",
            "Epoch: 024, AUC: 0.6223, AP: 0.6929\n",
            "Epoch: 025, AUC: 0.6231, AP: 0.6937\n",
            "Epoch: 026, AUC: 0.6234, AP: 0.6942\n",
            "Epoch: 027, AUC: 0.6241, AP: 0.6948\n",
            "Epoch: 028, AUC: 0.6254, AP: 0.6957\n",
            "Epoch: 029, AUC: 0.6279, AP: 0.6970\n",
            "Epoch: 030, AUC: 0.6308, AP: 0.6983\n",
            "Epoch: 031, AUC: 0.6345, AP: 0.6999\n",
            "Epoch: 032, AUC: 0.6393, AP: 0.7018\n",
            "Epoch: 033, AUC: 0.6445, AP: 0.7040\n",
            "Epoch: 034, AUC: 0.6506, AP: 0.7064\n",
            "Epoch: 035, AUC: 0.6583, AP: 0.7094\n",
            "Epoch: 036, AUC: 0.6675, AP: 0.7131\n",
            "Epoch: 037, AUC: 0.6773, AP: 0.7175\n",
            "Epoch: 038, AUC: 0.6863, AP: 0.7217\n",
            "Epoch: 039, AUC: 0.6950, AP: 0.7258\n",
            "Epoch: 040, AUC: 0.7043, AP: 0.7306\n",
            "Epoch: 041, AUC: 0.7141, AP: 0.7359\n",
            "Epoch: 042, AUC: 0.7244, AP: 0.7421\n",
            "Epoch: 043, AUC: 0.7325, AP: 0.7470\n",
            "Epoch: 044, AUC: 0.7391, AP: 0.7512\n",
            "Epoch: 045, AUC: 0.7447, AP: 0.7544\n",
            "Epoch: 046, AUC: 0.7496, AP: 0.7577\n",
            "Epoch: 047, AUC: 0.7534, AP: 0.7604\n",
            "Epoch: 048, AUC: 0.7575, AP: 0.7632\n",
            "Epoch: 049, AUC: 0.7612, AP: 0.7661\n",
            "Epoch: 050, AUC: 0.7638, AP: 0.7683\n",
            "Epoch: 051, AUC: 0.7661, AP: 0.7703\n",
            "Epoch: 052, AUC: 0.7682, AP: 0.7722\n",
            "Epoch: 053, AUC: 0.7698, AP: 0.7732\n",
            "Epoch: 054, AUC: 0.7710, AP: 0.7743\n",
            "Epoch: 055, AUC: 0.7722, AP: 0.7753\n",
            "Epoch: 056, AUC: 0.7734, AP: 0.7763\n",
            "Epoch: 057, AUC: 0.7742, AP: 0.7770\n",
            "Epoch: 058, AUC: 0.7754, AP: 0.7782\n",
            "Epoch: 059, AUC: 0.7767, AP: 0.7794\n",
            "Epoch: 060, AUC: 0.7776, AP: 0.7804\n",
            "Epoch: 061, AUC: 0.7786, AP: 0.7811\n",
            "Epoch: 062, AUC: 0.7792, AP: 0.7817\n",
            "Epoch: 063, AUC: 0.7799, AP: 0.7819\n",
            "Epoch: 064, AUC: 0.7804, AP: 0.7822\n",
            "Epoch: 065, AUC: 0.7809, AP: 0.7825\n",
            "Epoch: 066, AUC: 0.7814, AP: 0.7829\n",
            "Epoch: 067, AUC: 0.7820, AP: 0.7836\n",
            "Epoch: 068, AUC: 0.7825, AP: 0.7840\n",
            "Epoch: 069, AUC: 0.7832, AP: 0.7841\n",
            "Epoch: 070, AUC: 0.7829, AP: 0.7833\n",
            "Epoch: 071, AUC: 0.7829, AP: 0.7826\n",
            "Epoch: 072, AUC: 0.7835, AP: 0.7831\n",
            "Epoch: 073, AUC: 0.7836, AP: 0.7832\n",
            "Epoch: 074, AUC: 0.7842, AP: 0.7836\n",
            "Epoch: 075, AUC: 0.7844, AP: 0.7835\n",
            "Epoch: 076, AUC: 0.7842, AP: 0.7830\n",
            "Epoch: 077, AUC: 0.7841, AP: 0.7821\n",
            "Epoch: 078, AUC: 0.7841, AP: 0.7816\n",
            "Epoch: 079, AUC: 0.7838, AP: 0.7815\n",
            "Epoch: 080, AUC: 0.7835, AP: 0.7814\n",
            "Epoch: 081, AUC: 0.7834, AP: 0.7812\n",
            "Epoch: 082, AUC: 0.7835, AP: 0.7806\n",
            "Epoch: 083, AUC: 0.7835, AP: 0.7801\n",
            "Epoch: 084, AUC: 0.7835, AP: 0.7792\n",
            "Epoch: 085, AUC: 0.7835, AP: 0.7792\n",
            "Epoch: 086, AUC: 0.7836, AP: 0.7792\n",
            "Epoch: 087, AUC: 0.7835, AP: 0.7792\n",
            "Epoch: 088, AUC: 0.7833, AP: 0.7793\n",
            "Epoch: 089, AUC: 0.7835, AP: 0.7794\n",
            "Epoch: 090, AUC: 0.7837, AP: 0.7788\n",
            "Epoch: 091, AUC: 0.7842, AP: 0.7788\n",
            "Epoch: 092, AUC: 0.7843, AP: 0.7789\n",
            "Epoch: 093, AUC: 0.7844, AP: 0.7794\n",
            "Epoch: 094, AUC: 0.7839, AP: 0.7794\n",
            "Epoch: 095, AUC: 0.7838, AP: 0.7797\n",
            "Epoch: 096, AUC: 0.7838, AP: 0.7791\n",
            "Epoch: 097, AUC: 0.7844, AP: 0.7790\n",
            "Epoch: 098, AUC: 0.7843, AP: 0.7784\n",
            "Epoch: 099, AUC: 0.7845, AP: 0.7785\n",
            "Epoch: 100, AUC: 0.7844, AP: 0.7786\n"
          ]
        }
      ]
    }
  ]
}